{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT fine-tuning on IMDB video dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "from transformers import InputExample, InputFeatures\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test GPU configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU:\", tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'positive': 1, 'negative': 0}\n",
    "data = pd.read_csv(\"data/train.csv\") # imdb dataset from kaggle (https://www.kaggle.com/lakshmi25npathi/sentiment-analysis-of-imdb-movie-reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pretrained tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, id2label={v: k for k, v in label2id.items()}, use_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = data['sentiment'].map(label2id)\n",
    "# data = data.sample(1000) # take only some rows for speeding up train\n",
    "\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train = data[msk]\n",
    "test = data[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \n",
    "  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "  \n",
    "  return train_InputExamples, validation_InputExamples\n",
    "  \n",
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
    "    features = [] # -> will hold InputFeatures to be converted later\n",
    "\n",
    "    for e in examples:\n",
    "        # Documentation is really strong for this method, so please take a look at it\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length, # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True, # pads to the right by default\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
    "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2215: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, \"review\", \"sentiment\")\n",
    "\n",
    "train_dataset = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "train_dataset = train_dataset.shuffle(100).batch(32).repeat(2)\n",
    "\n",
    "validation_dataset = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "validation_dataset = validation_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_189 (Dropout)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 16:29:51.367771: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2502/Unknown - 4557s 2s/step - loss: 0.2424 - accuracy: 0.8982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 17:45:45.002972: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2502/2502 [==============================] - 4641s 2s/step - loss: 0.2424 - accuracy: 0.8982 - val_loss: 0.3048 - val_accuracy: 0.8868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a4f65220>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_dataset,\n",
    "  validation_data=validation_dataset,\n",
    "  epochs=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"output/model\")\n",
    "tokenizer.save_pretrained(\"output/model\")\n",
    "\n",
    "# Fix to remove the cache dependencies\n",
    "tokenizer_config_file = 'output/model/tokenizer_config.json'\n",
    "with open(tokenizer_config_file, 'r') as f:\n",
    "  d = json.load(f)\n",
    "  del d['tokenizer_file']\n",
    "  f.close()\n",
    "\n",
    "with open(tokenizer_config_file, 'w') as f:\n",
    "  json.dump(d, f, indent=2)\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(100)\n",
    "reviews = sample['review'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49205</th>\n",
       "      <td>When I first viewed this movie, I didn't know ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44540</th>\n",
       "      <td>To borrow from Dorothy Parker: This is not a f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44964</th>\n",
       "      <td>This was Charlie Chaplin's first all-talking f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30320</th>\n",
       "      <td>Although the director tried(the filming was ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45057</th>\n",
       "      <td>I'm stunt, I must admit I never saw a movie wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43587</th>\n",
       "      <td>When I first became a father about 5.5 years a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37768</th>\n",
       "      <td>Yet another movie with an interesting premise ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42600</th>\n",
       "      <td>This was a sordid and dreary mess. I needed a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48043</th>\n",
       "      <td>Comparing Oceans Twelve to the 2001 Oceans Ele...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41256</th>\n",
       "      <td>Best fan boy movie I've ever watched save \"Fre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49205  When I first viewed this movie, I didn't know ...          0\n",
       "44540  To borrow from Dorothy Parker: This is not a f...          0\n",
       "44964  This was Charlie Chaplin's first all-talking f...          1\n",
       "30320  Although the director tried(the filming was ma...          0\n",
       "45057  I'm stunt, I must admit I never saw a movie wi...          1\n",
       "...                                                  ...        ...\n",
       "43587  When I first became a father about 5.5 years a...          0\n",
       "37768  Yet another movie with an interesting premise ...          0\n",
       "42600  This was a sordid and dreary mess. I needed a ...          0\n",
       "48043  Comparing Oceans Twelve to the 2001 Oceans Ele...          0\n",
       "41256  Best fan boy movie I've ever watched save \"Fre...          1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('text-classification', model=model, tokenizer=tokenizer)\n",
    "predictions = classifier(reviews)\n",
    "\n",
    "y_test = sample['sentiment'].to_list()\n",
    "y_pred = [label2id[pred['label']] for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>46.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.954128</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.950505</td>\n",
       "      <td>0.948873</td>\n",
       "      <td>0.949592</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.950101</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.949955</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "positive       0.955556  0.934783  0.945055    46.00\n",
       "negative       0.945455  0.962963  0.954128    54.00\n",
       "accuracy       0.950000  0.950000  0.950000     0.95\n",
       "macro avg      0.950505  0.948873  0.949592   100.00\n",
       "weighted avg   0.950101  0.950000  0.949955   100.00"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, target_names=label2id.keys(), output_dict=True)\n",
    "pd.DataFrame(report).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = pd.DataFrame(confusion_matrix(y_test, y_pred, labels=range(2)), range(2), range(2))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
